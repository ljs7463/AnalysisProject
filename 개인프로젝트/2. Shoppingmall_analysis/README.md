## 여성 홈쇼핑 데이터 분석
---

파일 설명 
- 프로젝트 메인파일 : shopping_model_.ver2(log).ipynb 파일이 메인 파일입니다.
- function.ipynb : 로직구성을 위한 함수 임시저장
---
## 프로젝트를 시작 하게 된 이유
이커머스 시장에 관심이 많고 풍부한 데이터와 고객의 행동까지 다양하게 다루어 볼 수 있기 때문에 항상 이커머스 데이터를 찾아다니고 있던도 중 다른 데이터셋과 다르게
다양한 특징(column, feature)을 가진데이터를 발견함에 따라서 다양한 가설을 세워보고 검정해 볼 수 있으며, 개인의 창의력이나 기획역량 혹은 관점에따라 여러가지 분석의 방향이 정해질것 같아서 해당 데이터로 프로젝트를 시작하게 되었습니다.

---
## 프로젝트 목적
어떻게하면 상품이 잘 팔리는지를 최대한 다양한 접근에서 꾸준하게 분석해 보고 입점한 고객들이 상품에 대한 정보를 입력받았을때 판매를 예측해 주고 입력된 정보를 통해 보충해야할 부분을 간단하게 알려주는 기능을 설계하는것 입니다.


---
## 프로젝트 진행 방식

많은 특징(column, feature)들이 있는 만큼 컬럼에 따른 다양한 가설을 세워보고 가설에 답을하며 인사이트를 뽑아 내는 방식으로 진행을 함.

---
## 진행순서 및 진행 상황

애자일한 방식으로 전처리와 아주간단한 모델링과 로직을 구성하여 작동여부를 실험해보고 모델에 성능및 전처리 보완을 해나가는 방식으로 진행하며
feedback이후가 성능을 올리고 코드 개선 및 전처리 재검정 순서이다.

- [x]  데이터 탐색

- [x]  에러 데이터 탐색 및 수정
  
- [x]  가설검정

- [x]  임시 모델 만들기

- [x]  정보를 받았을때 예측 및 보충 부분 전달 로직 구성하기

- [x]  test

- [ ]  feedback(모델성능 강화를 지속적으로 진행하면서 test를 반복한다./ 코드개선 포함)

- [ ]  최종 모델 선정 및 코드 정리

---
## 프로젝트 진행하면서 어려웠던 부분 및 배운점
- 기본 전처리 단계의 중요성 -> 중복제거와 같은 기본단계의 실수나 놓친부분이 생기게 됨에 따라 가설검정의 결과가 달라졌음.
- 내가 한 가설검정의 방법이 적재적소에 맞게 쓴것인가?, 혹은 단순 시각화 만으로 확인할 수 있는 부분인데 가설검정으로 불필요한 시간을 소비한것은아닌가??
  -> 가장 고민이 많았던 어려운 점이었습니다. 기초 통계 스터디를 진행하고 있지만, 적용에 있어서 이 검정방법이 최선인지 더 좋은방법은 없는지, 정규성이나 등분산성의 환경에 따른 어떤
    유연함을 가져야하는지 등. 너무 다양한 요소들 속에서 많은 시간을 할애하고 있습니다. 논문을 통해서 사용한 가설검정을 어떻게 사용하였는지 검토해보고 지속적으로 가설검정, 전처리, 모델링등 업데이트를 할 예정입니다.  
- 특성공학 : 어떤 feature를 선택해야 하는가는 모델링에 있어서 중요한 부분이다. 다양한 feature selection 모델이 있지만 맞게 적용하는것을 생각하기 쉽지 않았다. 또한 특정 컬럼에 편향된
  결과를 마주하고 있는 지금 계속해서 학습하며 어떻게 수정할지 고민하고 있다.
- 데이터 셋 분리 타이밍 : 전체 데이터 프레임의 속성을 이용하는 전처리나 스케일링은 데이터셋 분리이후 진행하는 것이 맞지만 간단한 결측값을 채우는 것은 이전에도 가능하다고 생각하고 진행하였다.
- 자연발생 이상치의 경우 삭제가 힘들고 다양한 처리방법론이 있는데 스케일의 변화로 왜도와 같은 형태를 극복한 이후에도 여전히 분산, 최대값등이 높을때 어떻게 대처해야할지 계속해서 고민하고 학습을 이어가고 있다.






