{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljs7463/AnalysisProject/blob/master/%EB%8D%B0%EC%9D%B4%EC%BD%98/analytics/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbdf4d40",
      "metadata": {
        "id": "bbdf4d40"
      },
      "source": [
        "# import lib & data & func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d2fa1123",
      "metadata": {
        "id": "d2fa1123"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# 시각화 폰트 설정\n",
        "if os.name =='posix':\n",
        "    plt.rc(\"font\", family = \"AppleGothic\")\n",
        "\n",
        "else:\n",
        "    plt.rc(\"font\", family = \"Malgun Gothic\")\n",
        "\n",
        "# 경고문자 무시\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "74628b2b",
      "metadata": {
        "id": "74628b2b"
      },
      "outputs": [],
      "source": [
        "# 쥬피터 실행시\n",
        "# train_path = '../data/open/train.csv'\n",
        "# test_path = '../data/open/test.csv'\n",
        "# info_path = '../data/open/data_info.csv'\n",
        "# sub_path = '../data/open/sample_submission.csv'\n",
        "# df_train = pd.read_csv(train_path)\n",
        "# df_test = pd.read_csv(test_path)\n",
        "# df_info = pd.read_csv(info_path)\n",
        "# df_sub = pd.read_csv(sub_path)\n",
        "\n",
        "# 코랩 실행시\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_sub = pd.read_csv('sample_submission.csv')\n",
        "df_info = pd.read_csv('data_info.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "483c1e37",
      "metadata": {
        "id": "483c1e37"
      },
      "source": [
        "user_id:\t사용자의 고유 식별자\n",
        "\n",
        "subscription_duration:\t사용자가 서비스에 가입한 기간 (월)\n",
        "\n",
        "recent_login_time:\t사용자가 마지막으로 로그인한 시간 (일)\n",
        "\n",
        "average_login_time: \t사용자의 일반적인 로그인 시간\n",
        "\n",
        "average_time_per_learning_session:\t각 학습 세션에 소요된 평균 시간 (분)\n",
        "\n",
        "monthly_active_learning_days:\t월간 활동적인 학습 일수\n",
        "\n",
        "total_completed_courses:\t완료한 총 코스 수\n",
        "\n",
        "recent_learning_achievement: \t최근 학습 성취도\n",
        "\n",
        "abandoned_learning_sessions:\t중단된 학습 세션 수\n",
        "\n",
        "community_engagement_level:\t커뮤니티 참여도\n",
        "\n",
        "preferred_difficulty_level:\t선호하는 난이도\n",
        "\n",
        "subscription_type:\t구독 유형\n",
        "\n",
        "customer_inquiry_history:\t고객 문의 이력\n",
        "\n",
        "payment_pattern\n",
        "  사용자의 지난 3개월 간의 결제 패턴을 10진수로 표현한 값.\n",
        "  - 7: 3개월 모두 결제함\n",
        "  - 6: 첫 2개월은 결제했으나 마지막 달에는 결제하지 않음\n",
        "  - 5: 첫 달과 마지막 달에 결제함\n",
        "  - 4: 첫 달에만 결제함\n",
        "  - 3: 마지막 2개월에 결제함\n",
        "  - 2: 가운데 달에만 결제함\n",
        "  - 1: 마지막 달에만 결제함\n",
        "  - 0: 3개월 동안 결제하지 않음\n",
        "\n",
        "target:\t사용자가 다음 달에도 구독을 계속할지 (1) 또는 취소할지 (0)를 나타냄\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "66af2714",
      "metadata": {
        "id": "66af2714"
      },
      "outputs": [],
      "source": [
        "#  최근 학습 성취도 범주화\n",
        "def ach(x):\n",
        "    if x>=80:\n",
        "        x = 1\n",
        "    elif x >=60 and x <80:\n",
        "        x = 2\n",
        "    elif x >=40 and x <60:\n",
        "        x = 3\n",
        "    elif x >=20 and x <40:\n",
        "        x = 4\n",
        "    elif x < 20:\n",
        "        x = 5\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a61cef1",
      "metadata": {
        "id": "8a61cef1"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d155a097",
      "metadata": {
        "id": "d155a097"
      },
      "source": [
        "## 구독 유형&난이도 스케일링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a4f485a9",
      "metadata": {
        "id": "a4f485a9"
      },
      "outputs": [],
      "source": [
        "## Label Encoding\n",
        "\n",
        "## train데이터\n",
        "df_train['preferred_difficulty_level'] = pd.factorize(df_train['preferred_difficulty_level'])[0]\n",
        "df_train['subscription_type'] = pd.factorize(df_train['subscription_type'])[0]\n",
        "\n",
        "## test데이터\n",
        "df_test['preferred_difficulty_level'] = pd.factorize(df_test['preferred_difficulty_level'])[0]\n",
        "df_test['subscription_type'] = pd.factorize(df_test['subscription_type'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a4528e26",
      "metadata": {
        "id": "a4528e26"
      },
      "outputs": [],
      "source": [
        "## train 데이터\n",
        "df_train['recent_learning_achievement'] = df_train['recent_learning_achievement'].apply(lambda x: ach(x))\n",
        "\n",
        "## test 데이터\n",
        "df_test['recent_learning_achievement'] = df_test['recent_learning_achievement'].apply(lambda x: ach(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d12dde84",
      "metadata": {
        "id": "d12dde84"
      },
      "source": [
        "## 아웃라이어 있는컬럼 모두 스케일링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "db5fd86c",
      "metadata": {
        "id": "db5fd86c"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "for col in ['subscription_duration','recent_login_time','average_login_time','average_time_per_learning_session','monthly_active_learning_days','total_completed_courses','recent_learning_achievement']:\n",
        "    df_train[col] = scaler.fit_transform(df_train[[col]])\n",
        "\n",
        "\n",
        "\n",
        "## Label Encoding\n",
        "df_train['preferred_difficulty_level'] = pd.factorize(df_train['preferred_difficulty_level'])[0]\n",
        "df_train['subscription_type'] = pd.factorize(df_train['subscription_type'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "for col in ['subscription_duration','recent_login_time','average_login_time','average_time_per_learning_session','monthly_active_learning_days','total_completed_courses','recent_learning_achievement']:\n",
        "    df_test[col] = scaler.fit_transform(df_test[[col]])\n",
        "\n",
        "\n",
        "\n",
        "## Label Encoding\n",
        "df_test['preferred_difficulty_level'] = pd.factorize(df_test['preferred_difficulty_level'])[0]\n",
        "df_test['subscription_type'] = pd.factorize(df_test['subscription_type'])[0]"
      ],
      "metadata": {
        "id": "87w0MnkQ0eYa"
      },
      "id": "87w0MnkQ0eYa",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c9542b02",
      "metadata": {
        "id": "c9542b02"
      },
      "source": [
        "# Before Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "314efb66",
      "metadata": {
        "id": "314efb66"
      },
      "outputs": [],
      "source": [
        "# Delete user_id\n",
        "df_train = df_train.drop(columns = 'user_id')\n",
        "\n",
        "# split target\n",
        "x = df_train[list(df_train.columns[:-1])]\n",
        "y = df_train['target']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete user_id\n",
        "df_test = df_test.drop(columns = 'user_id')\n",
        "\n",
        "# split target\n",
        "new_x = df_test\n"
      ],
      "metadata": {
        "id": "nqpLrEWD0qON"
      },
      "id": "nqpLrEWD0qON",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4ebfa30f",
      "metadata": {
        "id": "4ebfa30f"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d75255",
      "metadata": {
        "id": "98d75255"
      },
      "source": [
        "- average_time_per_learning_session : 카테고리화 혹은 아웃라이어 제거후 진행도 해보기\n",
        "- 선호하는 난이도와 구독유형만 카테고리화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6dfd3fa",
      "metadata": {
        "id": "c6dfd3fa"
      },
      "source": [
        "첫 번째 실험\n",
        "- 선호하는 난이도와 구독유형만 카테고리화\n",
        "- catboost & gridsearch cv : 0.50548"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f42acfb",
      "metadata": {
        "id": "0f42acfb"
      },
      "source": [
        "## catBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a877f72b",
      "metadata": {
        "id": "a877f72b"
      },
      "source": [
        "### gridSearchCV  포함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "953a91df",
      "metadata": {
        "id": "953a91df",
        "outputId": "5fe0a591-4ca6-4749-b21d-3623027a98aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최적의 파라미터: {'depth': 5, 'iterations': 200, 'learning_rate': 0.1}\n",
            "최고 평균 Macro F1 점수: 0.4180639281423656\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# CatBoost 모델 설정\n",
        "model = CatBoostClassifier(verbose=False)\n",
        "\n",
        "# 탐색할 하이퍼파라미터 그리드 정의\n",
        "param_grid = {\n",
        "    'iterations': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# Macro F1 스코어를 사용하기 위한 스코어러 생성\n",
        "macro_f1_scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# GridSearchCV 설정\n",
        "grid_search = GridSearchCV(model, param_grid, cv=StratifiedKFold(5), scoring=macro_f1_scorer, n_jobs=-1)\n",
        "\n",
        "# GridSearchCV 실행\n",
        "grid_search.fit(x, y)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"최적의 파라미터:\", grid_search.best_params_)\n",
        "print(\"최고 평균 Macro F1 점수:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "371fdfbe",
      "metadata": {
        "id": "371fdfbe",
        "outputId": "461c9c66-aa5f-4b08-aad7-e9e7168de161"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39mStratifiedKFold(\u001b[38;5;241m5\u001b[39m), scoring\u001b[38;5;241m=\u001b[39mmacro_f1_scorer, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# GridSearchCV 실행\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최적의 파라미터:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\jupyter\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\jupyter\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\jupyter\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\jupyter\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\jupyter\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\jupyter\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\jupyter\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\jupyter\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# CatBoost 모델 설정\n",
        "model = CatBoostClassifier(verbose=False)\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [700,800,900,1000],\n",
        "    'learning_rate': [ 0.05, 0.1, 0.15],\n",
        "    'depth': [8,9,10,11],\n",
        "\n",
        "}\n",
        "\n",
        "# Macro F1 스코어를 사용하기 위한 스코어러 생성\n",
        "macro_f1_scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# GridSearchCV 설정\n",
        "grid_search = GridSearchCV(model, param_grid, cv=StratifiedKFold(5), scoring=macro_f1_scorer, n_jobs=-1)\n",
        "\n",
        "# GridSearchCV 실행\n",
        "grid_search.fit(x, y)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"최적의 파라미터:\", grid_search.best_params_)\n",
        "print(\"최고 평균 Macro F1 점수:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37cfe5f0",
      "metadata": {
        "id": "37cfe5f0"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "df_test['preferred_difficulty_level'] = pd.factorize(df_test['preferred_difficulty_level'])[0]\n",
        "df_test['subscription_type'] = pd.factorize(df_test['subscription_type'])[0]\n",
        "df_test['recent_learning_achievement'] = df_test['recent_learning_achievement'].apply(lambda x: ach(x))\n",
        "\n",
        "df_test = df_test.drop(columns = 'user_id')\n",
        "# 최적의 모델 가져오기\n",
        "best_model = grid_search.best_estimator_\n",
        "new_x = df_test[list(df_test)]\n",
        "# 새로운 데이터에 대한 예측 수행\n",
        "# 최적의 모델 가져오기\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions = best_model.predict(new_x)\n",
        "\n",
        "\n",
        "# 예측값 저장\n",
        "df_sub['target'] = predictions\n",
        "df_sub.set_index('user_id').to_csv('csv.csv', encoding=\"cp949\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e92802",
      "metadata": {
        "id": "41e92802"
      },
      "source": [
        "## xgBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "36d57a93",
      "metadata": {
        "id": "36d57a93",
        "outputId": "08412412-fa81-4e24-8c30-c67405ac1998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "최적의 파라미터: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
            "최고 평균 정확도: 0.5003549568555615\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 분할\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [5,7 ,9, 11],\n",
        "    'learning_rate': [0.1, 0.01, 0.05],\n",
        "    'n_estimators': [ 200, 300, 400, 500],\n",
        "    'colsample_bytree': [0.3, 0.7, 0.9]\n",
        "}\n",
        "\n",
        "# XGBoost 분류기 초기화\n",
        "xgb_classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "# Macro F1 스코어를 사용하기 위한 스코어러 생성\n",
        "macro_f1_scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# GridSearchCV 설정\n",
        "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, scoring = macro_f1_scorer, n_jobs=-1, verbose=1)\n",
        "\n",
        "# GridSearchCV 실행\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"최적의 파라미터:\", grid_search.best_params_)\n",
        "print(\"최고 평균 정확도:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67b44203",
      "metadata": {
        "id": "67b44203",
        "outputId": "bad248ed-c7a3-4212-c80d-edbadfc6fa1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Accuracy: 0.549\n"
          ]
        }
      ],
      "source": [
        "# 최적의 모델 가져오기\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 예측\n",
        "y_pred = best_model.predict(x_test)\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Set Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1bfc824",
      "metadata": {
        "id": "b1bfc824"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "df_test['preferred_difficulty_level'] = pd.factorize(df_test['preferred_difficulty_level'])[0]\n",
        "df_test['subscription_type'] = pd.factorize(df_test['subscription_type'])[0]\n",
        "df_test['recent_learning_achievement'] = df_test['recent_learning_achievement'].apply(lambda x: ach(x))\n",
        "\n",
        "df_test = df_test.drop(columns = 'user_id')\n",
        "# 최적의 모델 가져오기\n",
        "best_model = grid_search.best_estimator_\n",
        "new_x = df_test[list(df_test)]\n",
        "# 최적의 모델 가져오기\n",
        "best_model = grid_search.best_estimator_\n",
        "prediction = best_model.predict(new_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2430a5",
      "metadata": {
        "id": "6e2430a5"
      },
      "outputs": [],
      "source": [
        "# 예측값 저장\n",
        "df_sub['target'] = prediction\n",
        "df_sub.set_index('user_id').to_csv('csv.csv', encoding=\"cp949\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97dc27be",
      "metadata": {
        "id": "97dc27be"
      },
      "source": [
        "# Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "78e0b96c",
      "metadata": {
        "id": "78e0b96c"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "61b0a17f",
      "metadata": {
        "id": "61b0a17f",
        "outputId": "4d5f2f9c-4fc7-4476-a0bc-d2ef49682281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
            "[LightGBM] [Info] Number of positive: 4957, number of negative: 3043\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 663\n",
            "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.619625 -> initscore=0.487957\n",
            "[LightGBM] [Info] Start training from score 0.487957\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "최적의 파라미터: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500, 'num_leaves': 70}\n",
            "최고 평균 Macro F1 점수: 0.5109801209664911\n"
          ]
        }
      ],
      "source": [
        "# 데이터 분할\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "param_grid = {\n",
        "    'max_depth': [5,7 ,9, 11],\n",
        "    'learning_rate': [0.1, 0.01, 0.05],\n",
        "    'n_estimators': [ 200, 300, 400, 500],\n",
        "    'colsample_bytree': [0.3, 0.7, 0.9],\n",
        "    'num_leaves': [31, 50, 70],\n",
        "}\n",
        "# LightGBM 분류기 초기화\n",
        "lgb_classifier = lgb.LGBMClassifier()\n",
        "\n",
        "# Macro F1 스코어를 사용하기 위한 스코어러 생성\n",
        "macro_f1_scorer = make_scorer(f1_score, average='macro')\n",
        "\n",
        "# GridSearchCV 설정s\n",
        "grid_search = GridSearchCV(estimator=lgb_classifier, param_grid=param_grid, cv=3, scoring=macro_f1_scorer, n_jobs=-1, verbose=1)\n",
        "\n",
        "# GridSearchCV 실행\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"최적의 파라미터:\", grid_search.best_params_)\n",
        "print(\"최고 평균 Macro F1 점수:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5b371197",
      "metadata": {
        "id": "5b371197",
        "outputId": "9ff4b956-0178-4246-c48b-61ba2916cda7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Macro F1 Score: 0.48986505336489794\n"
          ]
        }
      ],
      "source": [
        "# 최적의 모델 가져오기\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 예측\n",
        "y_pred = best_model.predict(x_test)\n",
        "\n",
        "# Macro F1 점수 평가\n",
        "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "print(f\"Test Set Macro F1 Score: {macro_f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5708559b",
      "metadata": {
        "id": "5708559b"
      },
      "source": [
        "# scalling model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "gjo2qbXXxV_v"
      },
      "id": "gjo2qbXXxV_v"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "num_features = 13\n",
        "num_samples = 10000\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Reshape((num_features, 1), input_shape=(num_features,)))\n",
        "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(2))\n",
        "model.add(layers.Conv1D(64, 3, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "OP_AMywMxVIs",
        "outputId": "f7b91b73-d208-4c16-d448-bd391bd1900c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OP_AMywMxVIs",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_3 (Reshape)         (None, 13, 1)             0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 11, 32)            128       \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 5, 32)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 3, 64)             6208      \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Gl  (None, 64)                0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6401 (25.00 KB)\n",
            "Trainable params: 6401 (25.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def macro_f1_score(y_true, y_pred, threshold=0.5):\n",
        "    \"\"\"Macro F1 score 메트릭을 계산하는 함수.\"\"\"\n",
        "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
        "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p + r + K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[macro_f1_score])\n",
        "\n",
        "\n",
        "# 데이터 분할\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "smmJCXoFxyoU",
        "outputId": "b0f1e8cb-11c1-4320-e3a1-3cad5fcdfed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "smmJCXoFxyoU",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 4s 10ms/step - loss: 0.6655 - accuracy: 0.6133 - val_loss: 0.6584 - val_accuracy: 0.6205\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6592 - accuracy: 0.6183 - val_loss: 0.6644 - val_accuracy: 0.5915\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.6567 - accuracy: 0.6177 - val_loss: 0.6529 - val_accuracy: 0.6205\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6532 - accuracy: 0.6185 - val_loss: 0.6554 - val_accuracy: 0.6210\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6517 - accuracy: 0.6180 - val_loss: 0.6556 - val_accuracy: 0.6210\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6490 - accuracy: 0.6174 - val_loss: 0.6541 - val_accuracy: 0.6110\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6479 - accuracy: 0.6211 - val_loss: 0.6530 - val_accuracy: 0.6175\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.6479 - accuracy: 0.6156 - val_loss: 0.6534 - val_accuracy: 0.6210\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6459 - accuracy: 0.6206 - val_loss: 0.6517 - val_accuracy: 0.6080\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6431 - accuracy: 0.6152 - val_loss: 0.6695 - val_accuracy: 0.5360\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ef2f02adf90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "9_VFhEZSyZa_",
        "outputId": "30ebb5e8-752a-469c-b9ff-6b18be8aec9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9_VFhEZSyZa_",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 - 1s - loss: 0.6695 - accuracy: 0.5360 - 805ms/epoch - 13ms/step\n",
            "\n",
            "Test accuracy: 0.5360000133514404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 사용하여 예측 수행\n",
        "predictions = model.predict(new_x)"
      ],
      "metadata": {
        "id": "_l_sft1Xy2cp",
        "outputId": "9b019630-64d9-4b33-b480-9e374020dee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_l_sft1Xy2cp",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "xqBSvfOn1HGN",
        "outputId": "e3094087-d9b1-43e8-da11-b2deac51fd04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xqBSvfOn1HGN",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45686263],\n",
              "       [0.5640072 ],\n",
              "       [0.43610668],\n",
              "       ...,\n",
              "       [0.51791155],\n",
              "       [0.68737906],\n",
              "       [0.46402428]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임계값을 기준으로 예측 결과를 0과 1로 변환\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n"
      ],
      "metadata": {
        "id": "ixlM0rJl1NX_"
      },
      "id": "ixlM0rJl1NX_",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값 저장\n",
        "df_sub['target'] = binary_predictions\n",
        "df_sub.set_index('user_id').to_csv('cnn.csv', encoding=\"cp949\")"
      ],
      "metadata": {
        "id": "zkc5H-581ZrT"
      },
      "id": "zkc5H-581ZrT",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 0.51로 현재 최대"
      ],
      "metadata": {
        "id": "bjxqGHKH2Qy-"
      },
      "id": "bjxqGHKH2Qy-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN모델 튜닝"
      ],
      "metadata": {
        "id": "_GKkP7LL2TwS"
      },
      "id": "_GKkP7LL2TwS"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "num_features = 13\n",
        "num_samples = 10000\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Reshape((num_features, 1), input_shape=(num_features,)))\n",
        "model.add(layers.Conv1D(64, 3, activation='relu'))  # 필터 수 증가\n",
        "model.add(layers.MaxPooling1D(2))\n",
        "model.add(layers.Conv1D(64, 3, activation='relu', kernel_regularizer=regularizers.l2(0.001))) # L2 정규화 추가\n",
        "# model.add(layers.Conv1D(128, 3, activation='relu')) # 더 많은 필터\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dropout(0.5))                     # 드롭아웃 추가\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "def macro_f1_score(y_true, y_pred, threshold=0.5):\n",
        "    \"\"\"Macro F1 score 메트릭을 계산하는 함수.\"\"\"\n",
        "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
        "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p + r + K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[macro_f1_score])\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# 데이터 분할\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 조기 종료 콜백 추가\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "Ut2yJkLb2QMM",
        "outputId": "9e60a97f-e299-4baf-8391-2fd927a3f2af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ut2yJkLb2QMM",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 3s 12ms/step - loss: 0.7213 - macro_f1_score: 0.7433 - val_loss: 0.6946 - val_macro_f1_score: 0.7625\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6951 - macro_f1_score: 0.7586 - val_loss: 0.6822 - val_macro_f1_score: 0.7625\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6830 - macro_f1_score: 0.7631 - val_loss: 0.6739 - val_macro_f1_score: 0.7625\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6753 - macro_f1_score: 0.7633 - val_loss: 0.6689 - val_macro_f1_score: 0.7625\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6724 - macro_f1_score: 0.7628 - val_loss: 0.6638 - val_macro_f1_score: 0.7625\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6676 - macro_f1_score: 0.7631 - val_loss: 0.6615 - val_macro_f1_score: 0.7625\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6649 - macro_f1_score: 0.7637 - val_loss: 0.6590 - val_macro_f1_score: 0.7625\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6635 - macro_f1_score: 0.7638 - val_loss: 0.6581 - val_macro_f1_score: 0.7625\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6612 - macro_f1_score: 0.7633 - val_loss: 0.6562 - val_macro_f1_score: 0.7625\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6586 - macro_f1_score: 0.7631 - val_loss: 0.6563 - val_macro_f1_score: 0.7625\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6589 - macro_f1_score: 0.7634 - val_loss: 0.6538 - val_macro_f1_score: 0.7625\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6570 - macro_f1_score: 0.7633 - val_loss: 0.6542 - val_macro_f1_score: 0.7625\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6556 - macro_f1_score: 0.7638 - val_loss: 0.6518 - val_macro_f1_score: 0.7625\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6551 - macro_f1_score: 0.7636 - val_loss: 0.6520 - val_macro_f1_score: 0.7625\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6553 - macro_f1_score: 0.7637 - val_loss: 0.6526 - val_macro_f1_score: 0.7625\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6545 - macro_f1_score: 0.7637 - val_loss: 0.6507 - val_macro_f1_score: 0.7625\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6524 - macro_f1_score: 0.7635 - val_loss: 0.6520 - val_macro_f1_score: 0.7625\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6535 - macro_f1_score: 0.7635 - val_loss: 0.6509 - val_macro_f1_score: 0.7625\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6528 - macro_f1_score: 0.7638 - val_loss: 0.6506 - val_macro_f1_score: 0.7625\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6535 - macro_f1_score: 0.7633 - val_loss: 0.6507 - val_macro_f1_score: 0.7625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a90ed8ebcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "rTe-2JDF1iuv",
        "outputId": "16c8a5b9-5adb-4dfa-9a4e-61b0784d8d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rTe-2JDF1iuv",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 - 1s - loss: 0.6507 - macro_f1_score: 0.7612 - 580ms/epoch - 9ms/step\n",
            "\n",
            "Test accuracy: 0.7611902952194214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 사용하여 예측 수행\n",
        "predictions = model.predict(new_x)\n",
        "# 임계값을 기준으로 예측 결과를 0과 1로 변환\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n"
      ],
      "metadata": {
        "id": "KXeMmI6T2wCZ",
        "outputId": "8105c785-3833-4369-c059-1e0c88098551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KXeMmI6T2wCZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_predictions"
      ],
      "metadata": {
        "id": "iTvG_sDM21df",
        "outputId": "2e0e3da2-9966-4c3e-d430-0c7cc448b630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iTvG_sDM21df",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값 저장\n",
        "df_sub['target'] = binary_predictions\n",
        "df_sub.set_index('user_id').to_csv('cnn2.csv', encoding=\"cp949\")"
      ],
      "metadata": {
        "id": "B4X0OFzl25nh"
      },
      "id": "B4X0OFzl25nh",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN모델"
      ],
      "metadata": {
        "id": "1zU5HHHE7ghj"
      },
      "id": "1zU5HHHE7ghj"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score\n",
        "\n",
        "num_features = 13\n",
        "num_samples = 10000\n",
        "\n",
        "def macro_f1_score(y_true, y_pred, threshold=0.5):\n",
        "    \"\"\"Macro F1 score 메트릭을 계산하는 함수.\"\"\"\n",
        "    y_pred = K.cast(K.greater(y_pred, threshold), K.floatx())\n",
        "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p + r + K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "\n",
        "# 모델 구축\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(num_features,), kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[macro_f1_score])\n",
        "\n",
        "# 조기 종료 콜백 설정\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 분할\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 조기 종료 콜백 추가\n",
        "history = model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# 모델평가\n",
        "xtest_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "# tmp\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "# 모델을 사용하여 예측 수행\n",
        "predictions = model.predict(new_x)\n",
        "\n",
        "# 정밀도-재현율 곡선 계산\n",
        "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "# F1 점수 계산\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "f1_scores = f1_scores[~np.isnan(f1_scores)] # NaN 값 제거\n",
        "max_f1_index = np.argmax(f1_scores)\n",
        "best_threshold = thresholds_pr[max_f1_index]\n",
        "\n",
        "print(\"최적의 임계값:\", best_threshold)\n",
        "\n",
        "# 최종 예측\n",
        "final_predictions = (predictions > best_threshold).astype(int)\n",
        "print(\"최종 예측 결과:\\n\", final_predictions)"
      ],
      "metadata": {
        "id": "tckdmepV26nB",
        "outputId": "92e0aa26-92af-457e-8a54-c256ed04ad0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "tckdmepV26nB",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 3s 13ms/step - loss: 0.8126 - macro_f1_score: 0.6894 - val_loss: 0.7451 - val_macro_f1_score: 0.7594\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.7436 - macro_f1_score: 0.7370 - val_loss: 0.7337 - val_macro_f1_score: 0.7622\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.7248 - macro_f1_score: 0.7518 - val_loss: 0.7166 - val_macro_f1_score: 0.7625\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.7126 - macro_f1_score: 0.7570 - val_loss: 0.7023 - val_macro_f1_score: 0.7625\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.7012 - macro_f1_score: 0.7620 - val_loss: 0.6943 - val_macro_f1_score: 0.7625\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6976 - macro_f1_score: 0.7611 - val_loss: 0.6881 - val_macro_f1_score: 0.7625\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6898 - macro_f1_score: 0.7630 - val_loss: 0.6843 - val_macro_f1_score: 0.7625\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6855 - macro_f1_score: 0.7634 - val_loss: 0.6829 - val_macro_f1_score: 0.7625\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6793 - macro_f1_score: 0.7632 - val_loss: 0.6762 - val_macro_f1_score: 0.7625\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6769 - macro_f1_score: 0.7635 - val_loss: 0.6726 - val_macro_f1_score: 0.7625\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6741 - macro_f1_score: 0.7634 - val_loss: 0.6707 - val_macro_f1_score: 0.7625\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6710 - macro_f1_score: 0.7633 - val_loss: 0.6682 - val_macro_f1_score: 0.7625\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6686 - macro_f1_score: 0.7632 - val_loss: 0.6669 - val_macro_f1_score: 0.7625\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6652 - macro_f1_score: 0.7633 - val_loss: 0.6643 - val_macro_f1_score: 0.7625\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6645 - macro_f1_score: 0.7633 - val_loss: 0.6627 - val_macro_f1_score: 0.7625\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6629 - macro_f1_score: 0.7635 - val_loss: 0.6621 - val_macro_f1_score: 0.7625\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6615 - macro_f1_score: 0.7637 - val_loss: 0.6603 - val_macro_f1_score: 0.7625\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6592 - macro_f1_score: 0.7633 - val_loss: 0.6592 - val_macro_f1_score: 0.7625\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6588 - macro_f1_score: 0.7632 - val_loss: 0.6582 - val_macro_f1_score: 0.7625\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6572 - macro_f1_score: 0.7635 - val_loss: 0.6571 - val_macro_f1_score: 0.7625\n",
            "63/63 - 0s - loss: 0.6571 - macro_f1_score: 0.7612 - 112ms/epoch - 2ms/step\n",
            "\n",
            "Test accuracy: 0.7611902952194214\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d1a6d93cc2de>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# tmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreidct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'preidct'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값 저장\n",
        "df_sub['target'] = final_predictions\n",
        "df_sub.set_index('user_id').to_csv('cnn2.csv', encoding=\"cp949\")"
      ],
      "metadata": {
        "id": "DCVDTD_o8b8c"
      },
      "id": "DCVDTD_o8b8c",
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jupyter",
      "language": "python",
      "name": "jupyter"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "307.2px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}